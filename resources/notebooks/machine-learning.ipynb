{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Example\n",
    "\n",
    "This notebook is used to practice machine learning using Spark.  It shows some of the things that can be done for the various steps once we have a training and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql import functions as sqlf\n",
    "from pyspark.sql import types as sqlt\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_p = [('John',19),('Smith',29),('Adam',35),('Henry',50)]\n",
    "rdd = sc.parallelize(list_p)\n",
    "ppl = rdd.map(lambda x: Row(name=x[0], age=int(x[1])))\n",
    "DF_ppl = sqlContext.createDataFrame(ppl)\n",
    "DF_ppl.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- premise: string (nullable = true)\n",
      " |-- hypothesis: string (nullable = true)\n",
      " |-- lang_abv: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#url = \"https://raw.githubusercontent.com/guru99-edu/R-Programming/master/adult_data.csv\"\n",
    "#sc.addFile(url)\n",
    "sc.addFile('machine-learning/train.csv')\n",
    "df = sqlContext.read.csv(SparkFiles.get(\"train.csv\"), header=True, inferSchema= True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               label|count|\n",
      "+--------------------+-----+\n",
      "|                  en|    9|\n",
      "|To keep the peace...|    1|\n",
      "|                   0| 4158|\n",
      "|             English|   42|\n",
      "|     It was destiny.|    1|\n",
      "|To keep the peace...|    1|\n",
      "|The man yelled th...|    1|\n",
      "| continued the Co...|    2|\n",
      "|                   1| 3862|\n",
      "|The man exclaimed...|    1|\n",
      "|                   2| 4042|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It looks like some labels are bad\n",
    "\n",
    "df.groupby('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|        id|             premise|          hypothesis|            lang_abv|            language|               label|\n",
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|dd4f0d9f25|\"\"\"If you people ...| you wouldn't jok...|Many people have ...|                  en|             English|\n",
      "|ad4b9214af|\" \"\"So your girl ...| eh?\"\" he chortled.\"|Your farewell act...|                  en|             English|\n",
      "|bc400f6df7|\"This is one of t...| if you must wors...|\"\"\"We shouldn't w...| why do we even h...|                  en|\n",
      "|26b2abe32d|\"We need to be su...|            for once| seemed tongue-ti...|Tuppence was shoc...|                  en|\n",
      "|34fe3bf8ea|\"Well, we will co...| her hands folded...| and her grey hai...|Dorcas will be as...|                  en|\n",
      "|218c1a9db3|\"Very well ‚Äùbut i...|  and went inside. \"|Poirot sped right...|                  en|             English|\n",
      "|3a1bff7d40|\"You claimed to b...| using a diamond ...|Hanson leaned in ...|                  en|             English|\n",
      "|843a5631a0|I see, said Tuppe...|\"\"\"I can't compre...|\"\" said Tuppence ...|                  en|             English|\n",
      "|5b59a7eff8|\" \"\"You're not go...| do you hear?\"\" h...|\"\"\"You will not t...|                  en|             English|\n",
      "|247940ac05|\"But you might as...| \"\"It's always be...|If you don't beli...|                  en|             English|\n",
      "|d4709c7130|\"Ask Cook if she'...| and keep the pea...| was likely to pr...| and I did not en...|To keep the peace...|\n",
      "|55124575f2|We are assured of...|\"\"\"We are going t...|       aren't we?\"\"\"|                  en|             English|\n",
      "|19e0437138|\"You claimed to b...| using a diamond ...|Hanson's nose was...|                  en|             English|\n",
      "|87bd9b46a7|For example, Bruc...|\" \"\"The Man Nobod...|  \"\" by Bruce Barton| was never a best...|                  en|\n",
      "|72529a78bc|\"Just like we hav...| and Tuppence beg...|Tommy handed Tupp...|                  en|             English|\n",
      "|1b7e1c623d|\" \"\"So your girl ...| eh?\"\" he chortled.\"|Your little girl ...|                  en|             English|\n",
      "|81ed404c11|      \"I leap!\"\" And|       in very truth| run and leap he did| gambolling wildl...|The man exclaimed...|\n",
      "|8c2a870621|\"Ask Cook if she'...| and keep the pea...| was likely to pr...| and I did not en...|To keep the peace...|\n",
      "|52a5382125|\"In the meantime ...| the three search...|Their search for ...|                  en|             English|\n",
      "|08510dd69a|\"In the meantime ...| the three search...|The three searche...|                  en|             English|\n",
      "+----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here are the ones without the right labels\n",
    "\n",
    "df.filter(~df.label.isin([0,1,2])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----------+--------+--------+-----+\n",
      "| id|premise|hypothesis|lang_abv|language|label|\n",
      "+---+-------+----------+--------+--------+-----+\n",
      "|  0|      0|         0|       0|       0|    0|\n",
      "+---+-------+----------+--------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here's the null count\n",
    "\n",
    "df.agg(*[sqlf.count(sqlf.when(sqlf.isnull(c), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0| 4158|\n",
      "|    1| 3862|\n",
      "|    2| 4042|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_df = df.filter(df.label.isin([0,1,2]))\n",
    "clean_df.groupby('label').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make label numeric\n",
    "clean_df = clean_df.withColumn('label', clean_df['label'].cast(sqlt.FloatType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+\n",
      "| language|language_index|\n",
      "+---------+--------------+\n",
      "|  English|           0.0|\n",
      "|  English|           0.0|\n",
      "|   French|           3.0|\n",
      "|  English|           0.0|\n",
      "|     Thai|          10.0|\n",
      "|  Turkish|          13.0|\n",
      "|     Urdu|           5.0|\n",
      "|  English|           0.0|\n",
      "|  English|           0.0|\n",
      "|  Russian|           7.0|\n",
      "|Bulgarian|          14.0|\n",
      "|   German|          12.0|\n",
      "|   Arabic|           2.0|\n",
      "|  Chinese|           1.0|\n",
      "|    Hindi|           8.0|\n",
      "|  Swahili|           4.0|\n",
      "|  English|           0.0|\n",
      "|  English|           0.0|\n",
      "|  English|           0.0|\n",
      "|  English|           0.0|\n",
      "+---------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding is something that can do done for categorical columns\n",
    "# we start by converting language values to a number\n",
    "\n",
    "# assign an index number to each category using a string indexer\n",
    "language_indexer = StringIndexer(inputCol='language',outputCol='language_index')\n",
    "clean_df = language_indexer.fit(clean_df).transform(clean_df)\n",
    "clean_df.select(['language','language_index']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+---------------+\n",
      "| language|language_index|   language_ohe|\n",
      "+---------+--------------+---------------+\n",
      "|  English|           0.0| (14,[0],[1.0])|\n",
      "|  English|           0.0| (14,[0],[1.0])|\n",
      "|   French|           3.0| (14,[3],[1.0])|\n",
      "|  English|           0.0| (14,[0],[1.0])|\n",
      "|     Thai|          10.0|(14,[10],[1.0])|\n",
      "|  Turkish|          13.0|(14,[13],[1.0])|\n",
      "|     Urdu|           5.0| (14,[5],[1.0])|\n",
      "|  English|           0.0| (14,[0],[1.0])|\n",
      "|  English|           0.0| (14,[0],[1.0])|\n",
      "|  Russian|           7.0| (14,[7],[1.0])|\n",
      "|Bulgarian|          14.0|     (14,[],[])|\n",
      "|   German|          12.0|(14,[12],[1.0])|\n",
      "|   Arabic|           2.0| (14,[2],[1.0])|\n",
      "|  Chinese|           1.0| (14,[1],[1.0])|\n",
      "|    Hindi|           8.0| (14,[8],[1.0])|\n",
      "|  Swahili|           4.0| (14,[4],[1.0])|\n",
      "|  English|           0.0| (14,[0],[1.0])|\n",
      "|  English|           0.0| (14,[0],[1.0])|\n",
      "|  English|           0.0| (14,[0],[1.0])|\n",
      "|  English|           0.0| (14,[0],[1.0])|\n",
      "+---------+--------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create one-hot encoder for language\n",
    "language_encoder = OneHotEncoder(inputCols=['language_index'],outputCols=['language_ohe'])\n",
    "clean_df = language_encoder.fit(clean_df).transform(clean_df)\n",
    "clean_df.select(['language','language_index','language_ohe']).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use word embeddings to vectorize string columns (maybe BERT?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|        id|       features|\n",
      "+----------+---------------+\n",
      "|5130fd2cb5| (14,[0],[1.0])|\n",
      "|5b72532a0b| (14,[0],[1.0])|\n",
      "|3931fbe82a| (14,[3],[1.0])|\n",
      "|5622f0c60b| (14,[0],[1.0])|\n",
      "|86aaa48b45|(14,[10],[1.0])|\n",
      "|ed7d6a1e62|(14,[13],[1.0])|\n",
      "|5a0f4908a0| (14,[5],[1.0])|\n",
      "|fdcd1bd867| (14,[0],[1.0])|\n",
      "|7cfb3d272c| (14,[0],[1.0])|\n",
      "|8c10229663| (14,[7],[1.0])|\n",
      "|a1971593d5|     (14,[],[])|\n",
      "|2bf4b86d4f|(14,[12],[1.0])|\n",
      "|91b03f6bf4| (14,[2],[1.0])|\n",
      "|4c25aa4c06| (14,[1],[1.0])|\n",
      "|82f24422eb| (14,[8],[1.0])|\n",
      "|6d63ae6397| (14,[4],[1.0])|\n",
      "|0a3f52c547| (14,[0],[1.0])|\n",
      "|4b0eca3ccb| (14,[0],[1.0])|\n",
      "|cad235551c| (14,[0],[1.0])|\n",
      "|d8b3a4fb06| (14,[0],[1.0])|\n",
      "+----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assemble a features column that can be used for creating a model later\n",
    "# TODO: add vectors from word embeddings\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['language_ohe'], outputCol=\"features\")\n",
    "clean_df = assembler.transform(clean_df)\n",
    "clean_df.select(['id','features']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----+----------+\n",
      "|        id| language|label|prediction|\n",
      "+----------+---------+-----+----------+\n",
      "|5130fd2cb5|  English|  0.0|       0.0|\n",
      "|5b72532a0b|  English|  2.0|       0.0|\n",
      "|3931fbe82a|   French|  0.0|       0.0|\n",
      "|5622f0c60b|  English|  0.0|       0.0|\n",
      "|86aaa48b45|     Thai|  1.0|       1.0|\n",
      "|ed7d6a1e62|  Turkish|  0.0|       2.0|\n",
      "|5a0f4908a0|     Urdu|  0.0|       2.0|\n",
      "|fdcd1bd867|  English|  2.0|       0.0|\n",
      "|7cfb3d272c|  English|  1.0|       0.0|\n",
      "|8c10229663|  Russian|  0.0|       0.0|\n",
      "|a1971593d5|Bulgarian|  0.0|       0.0|\n",
      "|2bf4b86d4f|   German|  1.0|       2.0|\n",
      "|91b03f6bf4|   Arabic|  0.0|       2.0|\n",
      "|4c25aa4c06|  Chinese|  2.0|       1.0|\n",
      "|82f24422eb|    Hindi|  2.0|       2.0|\n",
      "|6d63ae6397|  Swahili|  0.0|       0.0|\n",
      "|0a3f52c547|  English|  0.0|       0.0|\n",
      "|4b0eca3ccb|  English|  1.0|       0.0|\n",
      "|cad235551c|  English|  2.0|       0.0|\n",
      "|d8b3a4fb06|  English|  2.0|       0.0|\n",
      "+----------+---------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use logistic regression\n",
    "model = LogisticRegression(featuresCol='features',labelCol='label')\n",
    "clean_df = model.fit(clean_df).transform(clean_df)\n",
    "clean_df.select(['id','language','label','prediction']).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- premise: string (nullable = true)\n",
      " |-- hypothesis: string (nullable = true)\n",
      " |-- lang_abv: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sc.addFile('machine-learning/test.csv')\n",
    "test_df = sqlContext.read.csv(SparkFiles.get(\"test.csv\"), header=True, inferSchema= True)\n",
    "test_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
